{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# PaLM Challenge Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "You've just spent some time running through many of the elements related to Google's PaLM API, its use and its API. This challenge lab is designed to test your knoledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQT500QqVPIb",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Objectives\n",
    "\n",
    "- Load the Vertex AI language models\n",
    "- Authenticate your environment\n",
    "- Demonstrate the use of prompt design, ideation, text classification, and text extraction\n",
    "\n",
    "Most of the following Python notebook cells have missing or incomplete code sections. Your challenge is to complete each cell, run it to test for correctness, and then move on. When all the cells are working, you have completed the challenge.\n",
    "\n",
    "**Note: The notebooks used in the PaLM labs may all be viewed directly on Github [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Install Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kc4WxYmLSBW5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.51.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.52.0-py2.py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.29.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.22.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.15)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (4.11.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.2.2)\n",
      "Downloading google_cloud_aiplatform-1.52.0-py2.py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.52.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Complete the following pip command\n",
    "!pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart your notebook Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "* Use the instructions found [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env) in the block below, insert the lines required to set the project ID and location (us-central1 works for sure) variables. Then import and initialize the vertexai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LCaCx6PLSBW6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insert the requisite steps here\n",
    "PROJECT_ID = \"qwiklabs-gcp-04-1622f8a854a2\"\n",
    "LOCATION = \"us-central1\" \n",
    "\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### Import libraries\n",
    "Import the following language model classes:\n",
    "- ChatModel\n",
    "- InputOutputTextPair\n",
    "- TextEmbeddingModel\n",
    "- TextGenerationModel\n",
    "\n",
    "from the Vertex AI, preview, language models module. \n",
    "\n",
    "For display purposes, also import Markdown and display from IPython display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4zjV4alsiVql",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete the two imports\n",
    "from vertexai.preview.language_models import ChatModel, InputOutputTextPair, TextEmbeddingModel, TextGenerationModel\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Google's PaLM technology to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4437b7608c8e"
   },
   "source": [
    "#### Load the model\n",
    "\n",
    "Instantiate a TextGenerationModel and save it to the `generation_model` variable. For this notebook, use `text-bison@002` as your model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2998506fe6d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEAJ0ipmbndQ"
   },
   "source": [
    "### Prompt design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCgBDJvNRCF5"
   },
   "source": [
    "Create a prediction around the prompt, \"Tell me about Google's PaLM API.\" Set the `temperature` to 0 and and set the `max_output_tokens` for the longest response possible with the text-bison@002 model. Leave the top_k and top_p with their defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model:  The PaLM API (Pathways Language Model) is a large language model developed by Google AI. It is a transformer-based language model that has been trained on a massive dataset of text and code. PaLM stands for Pathways Language Model, and it is part of Google's Pathways project, which aims to develop a unified AI architecture that can be used for a wide range of tasks.\n",
      "\n",
      "PaLM is a very powerful language model, and it has been shown to achieve state-of-the-art results on a variety of natural language processing tasks, including text generation, translation, question answering, and summarization. PaLM is also able to generate code, and it has been used to develop new software applications.\n",
      "\n",
      "The PaLM API is available to developers through Google Cloud, and it can be used to build a variety of natural language processing applications. The API provides a set of pre-trained models that can be used for different tasks, and it also allows developers to train their own custom models.\n",
      "\n",
      "Here are some of the key features of the PaLM API:\n",
      "\n",
      "* **Large-scale training:** PaLM has been trained on a massive dataset of text and code, which gives it a deep understanding of language and the ability to perform a wide range of tasks.\n",
      "* **State-of-the-art performance:** PaLM has achieved state-of-the-art results on a variety of natural language processing tasks, including text generation, translation, question answering, and summarization.\n",
      "* **Code generation:** PaLM is able to generate code, and it has been used to develop new software applications.\n",
      "* **Flexibility:** The PaLM API provides a set of pre-trained models that can be used for different tasks, and it also allows developers to train their own custom models.\n",
      "\n",
      "The PaLM API is a powerful tool that can be used to build a variety of natural language processing applications. It is a promising technology that has the potential to revolutionize the way we interact with computers.\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"max_output_tokens\": 2048,\n",
    "    \"temperature\": 0\n",
    "}\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "response = model.predict(\n",
    "    \"\"\"Tell me about Google\\'s PaLM API\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BP1BKWiRCF6"
   },
   "source": [
    "Use the below template to get your model to give you 5 title ideas for a training course on Google's Generative AI technologies. Once again, set the model’s prediction temperature to 0. \n",
    "\n",
    "Use display and Markdown to render the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2USfPyOuFhlB",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " 1. **Unlocking the Power of Google's Generative AI: A Comprehensive Guide**\n",
       "2. **Mastering Google's Generative AI: From Basics to Advanced Applications**\n",
       "3. **Harnessing the Potential of Google's Generative AI for Business Growth**\n",
       "4. **Exploring the Frontiers of Google's Generative AI: A Hands-On Approach**\n",
       "5. **Demystifying Google's Generative AI: A Beginner's Guide to Cutting-Edge Technologies**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Give 5 title ideas for a training course on Google\\'s Generative AI technologies\"\"\"\n",
    "\n",
    "response = model.predict(prompt, **parameters)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification\n",
    "Let's try a language classification problem. Using the below starting code, determine the language of: \"Es viernes todavía.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt = \"\"\"\n",
    "Given ...\n",
    "text: ...\n",
    "language:\n",
    "\"\"\"\n",
    "\n",
    "# add code to print the prediction using the defaults for temperature, max output tokens, top_p and k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are a little wordy, use one-shot prompting to get the prediction to return a single word to you, the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " text: Es viernes todaví?\n",
      "language: Spanish\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given the following text, classify the language it is written in.\n",
    "\n",
    "Replace this with the one-shot\n",
    "\n",
    "text: Es viernes todaví?\n",
    "language:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    model.predict(\n",
    "        prompt=prompt,\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Extraction\n",
    "Print the following list of cooking ingredients to a YAML format. Each ingredient should be listed with keys for **ingredient** and **quantity**, with each key having the correct value given the ingredients in the following recipe:\n",
    "\n",
    "Ingredients\n",
    "* 9 egg whites\n",
    "* 3/8 tsp Cream of Tartar\n",
    "* 1 1/2 tbs Vinegar\n",
    "* 1 1/2 tsp Vanilla\n",
    "* 3 cups Sugar\n",
    "* 1 quarts Heavy whipping cream\n",
    "* 3 boxes Strawberries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ```json\n",
      "{\n",
      "  \"ingredients\": [\n",
      "    {\n",
      "      \"ingredient\": \"egg whites\",\n",
      "      \"quantity\": 9,\n",
      "      \"type\": null\n",
      "    },\n",
      "    {\n",
      "      \"ingredient\": \"Cream of Tartar\",\n",
      "      \"quantity\": \"3/8 tsp\",\n",
      "      \"type\": null\n",
      "    },\n",
      "    {\n",
      "      \"ingredient\": \"Viniger\",\n",
      "      \"quantity\": \"1 1/2 tbs\",\n",
      "      \"type\": null\n",
      "    },\n",
      "    {\n",
      "      \"ingredient\": \"Vanilla\",\n",
      "      \"quantity\": \"1 1/2 tsp\",\n",
      "      \"type\": null\n",
      "    },\n",
      "    {\n",
      "      \"ingredient\": \"Sugar\",\n",
      "      \"quantity\": 3,\n",
      "      \"type\": \"cups\"\n",
      "    },\n",
      "    {\n",
      "      \"ingredient\": \"Heavy whipping cream\",\n",
      "      \"quantity\": 1,\n",
      "      \"type\": \"quarts\"\n",
      "    },\n",
      "    {\n",
      "      \"ingredient\": \"Strawberries\",\n",
      "      \"quantity\": 3,\n",
      "      \"type\": \"boxes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Extract the ingredients from the following recipe. Return the ingredients in JSON format with keys: ingredient, quantity, type.\n",
    "\n",
    "Ingredients\n",
    "\n",
    "9 egg whites\n",
    "3/8 tsp Cream of Tartar\n",
    "1 1/2 tbs Viniger\n",
    "1 1/2 tsp Vanilla\n",
    "3 cups Sugar\n",
    "1 quarts Heavy whipping cream\n",
    "3 boxes Strawberries\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "    ).text\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent work. You have now demonstrated your ability to use many key features in Google's PaLM library. Nice job.We likely want some nice wrapup here, but I don't know what, ha"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_palm_api.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": ".m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
